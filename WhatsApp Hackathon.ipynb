{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.parser import parse\n",
    "\n",
    "def is_date(string, fuzzy=False):\n",
    "    \"\"\"\n",
    "    Return whether the string can be interpreted as a date.\n",
    "\n",
    "    :param string: str, string to check for date\n",
    "    :param fuzzy: bool, ignore unknown tokens in string if True\n",
    "    \"\"\"\n",
    "    try: \n",
    "        parse(string, fuzzy=fuzzy)\n",
    "        return True\n",
    "\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_messages_to_list(f):\n",
    "    \"\"\"\n",
    "    Convert WhatsApp Messages from File to List\n",
    "    \n",
    "    :param f: FileBuffer, FileBuffer with the opened file in read mode\n",
    "    :return lines: List of WhatsApp Messages in 2 dimensional list\n",
    "    \"\"\"\n",
    "    lines = []\n",
    "    for line in f.readlines():\n",
    "        line_list = line.replace(\"\\n\",\"\").split(\",\")\n",
    "        if is_date(line_list[0]):\n",
    "            lines.append([line_list[0],(\"\".join(line_list[1:]))])\n",
    "        else:\n",
    "            lines[-1][-1] = lines[-1][-1] +' '+ line.replace(\"\\n\",\"\")\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"WhatsApp Chat with The Devs from Z.txt\", \"r\")\n",
    "messages = convert_messages_to_list(f)\n",
    "whatsapp_df = pd.DataFrame(messages,columns=['date','message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the Time and the Message from the DataFrame\n",
    "time_msg = whatsapp_df[\"message\"].str.split(\"-\", n = 1, expand = True)\n",
    "whatsapp_df[\"time\"] = time_msg[0]\n",
    "whatsapp_df[\"message\"] = time_msg[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the User Who Posted the Message and The Actual Message\n",
    "user_msg = whatsapp_df[\"message\"].str.split(\":\", n = 1, expand = True)\n",
    "whatsapp_df[\"user\"] = user_msg[0]\n",
    "whatsapp_df[\"message\"] = user_msg[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Null Values i.e. for Messages which do not have a User e.g. \"User Was Added To Group\" e.t.c.\n",
    "whatsapp_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_url(message):\n",
    "    \"\"\"\n",
    "    Regex to Extract URLs from Messages (Stackoverflow Help :smiley:)\n",
    "    \"\"\"\n",
    "    url = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', message)\n",
    "    return url[0] if url else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a New Column Called URL which has the Returned URL\n",
    "whatsapp_df[\"url\"] = whatsapp_df[\"message\"].apply(extract_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a New DataFrame with URLs Only\n",
    "whatsapp_grp_url = whatsapp_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write URL's to File\n",
    "whatsapp_grp_url.to_csv('URLs.txt', columns=[\"date\",\"user\",\"url\"], index=None, mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_urls = whatsapp_grp_url['url'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export to Chrome Bookmarks HTML File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def date_to_webkit(date_time):\n",
    "    epoch_start = datetime(1601, 1, 1)\n",
    "    date_ = date_time\n",
    "    diff = date_ - epoch_start\n",
    "    seconds_in_day = 60 * 60 * 24\n",
    "    return '{:<017d}'.format(\n",
    "        diff.days * seconds_in_day + diff.seconds + diff.microseconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_header=f\"\"\"<!DOCTYPE NETSCAPE-Bookmark-file-1>\n",
    "<!-- This is an automatically generated file. It will be read and overwritten. DO NOT EDIT! -->\n",
    "<META HTTP-EQUIV=\"Content-Type\" CONTENT=\"text/html; charset=UTF-8\">\n",
    "<TITLE>Bookmarks</TITLE>\n",
    "<H1>Bookmarks</H1>\n",
    "<DL><p>\n",
    "    <DT><H3 ADD_DATE=\"{date_to_webkit(datetime.now())}\" LAST_MODIFIED=\"\">Whatsapp Imports</H3>\n",
    "    <DL><p>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookmark_file = []\n",
    "bookmark_file.append(standard_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_page_name(url):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.3'}\n",
    "    request = urllib.request.Request(url=url, headers=headers)\n",
    "    soup = BeautifulSoup(urllib.request.urlopen(request))\n",
    "    if soup.title:\n",
    "        if soup.title.string:\n",
    "            return soup.title.string.replace(\"\\n\",\"\")\n",
    "        else:\n",
    "            return \"No Title\"\n",
    "    else:\n",
    "        return \"No Title\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in list_of_urls:\n",
    "    bookmark_file.append(f'\\t\\t<DT><A HREF=\"{url}\" ADD_DATE=\"{date_to_webkit(datetime.now())}\" ICON=\"\">{extract_page_name(url)}</A>\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookmark_file.append(f'''\\t<DL><p>\n",
    "<DL><p>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('chrome_bookmark.html', 'w') as bookmark_html:\n",
    "    for line in bookmark_file:\n",
    "        bookmark_html.write(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
